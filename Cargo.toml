[package]
name = "omen-cli"
version = "4.8.0"
edition = "2021"
rust-version = "1.92"
authors = ["Panbanda"]
license = "Apache-2.0"
description = "Multi-language code analysis CLI for AI assistants"
repository = "https://github.com/panbanda/omen"
keywords = ["code-analysis", "complexity", "technical-debt", "mcp", "cli"]
categories = ["command-line-utilities", "development-tools"]

[lib]
name = "omen"
path = "src/lib.rs"

[[bin]]
name = "omen"
path = "src/main.rs"

[dependencies]
# CLI
clap = { version = "4.5", features = ["derive", "env", "cargo"] }

# Error handling
thiserror = "2.0"
anyhow = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.9"

# Tree-sitter for parsing
tree-sitter = "0.24"
streaming-iterator = "0.1"
tree-sitter-go = "0.23"
tree-sitter-rust = "0.23"
tree-sitter-python = "0.23"
tree-sitter-typescript = "0.23"
tree-sitter-javascript = "0.23"
tree-sitter-java = "0.23"
tree-sitter-c = "0.23"
tree-sitter-cpp = "0.23"
tree-sitter-c-sharp = "0.23"
tree-sitter-ruby = "0.23"
tree-sitter-php = "0.23"
tree-sitter-bash = "0.23"

# Git operations
gix = { version = "0.68", default-features = false, features = ["blocking-network-client", "blocking-http-transport-reqwest-rust-tls", "revision", "blob-diff", "merge"] }

# Parallelism
rayon = "1.10"

# File operations
ignore = "0.4"
walkdir = "2.5"
globset = "0.4"

# Graph algorithms
petgraph = "0.8"

# Hashing
xxhash-rust = { version = "0.8", features = ["xxh3"] }
blake3 = "1.5"

# Progress reporting
indicatif = "0.18"

# HTTP for remote repos (MCP server)
reqwest = { version = "0.12", default-features = false, features = ["rustls-tls", "blocking", "json"] }
tokio = { version = "1.42", features = ["rt-multi-thread", "macros", "io-std", "sync"] }

# MCP server (JSON-RPC)
jsonrpsee = { version = "0.26", features = ["server"] }
tower = "0.5"

# Logging and colors
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
colored = "3.0"

# Regex
regex = "1.11"

# Date/time
chrono = { version = "0.4", default-features = false, features = ["std", "clock", "serde"] }

# HTML report templating
minijinja = { version = "2.5", features = ["builtins"] }
pulldown-cmark = "0.13"

# Utilities
once_cell = "1.20"
parking_lot = "0.12"
memmap2 = "0.9"
bstr = "1.11"
unicode-width = "0.2"

# Semantic search (all-MiniLM-L6-v2 sentence transformer, 384-dim embeddings)
# Model: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
# Runtime: candle for local inference, with optional third-party API providers
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"
hf-hub = { version = "0.4", features = ["tokio"] }
rusqlite = { version = "0.38", features = ["bundled"] }
tokenizers = { version = "0.22", default-features = false, features = ["onig"] }
dirs = "6.0"

[dev-dependencies]
# Testing
insta = { version = "1.41", features = ["json", "yaml"] }
proptest = "1.5"
criterion = { version = "0.5", features = ["html_reports"] }
tempfile = "3.14"
assert_cmd = "2.0"
predicates = "3.1"

[profile.release]
lto = "thin"
codegen-units = 1
strip = true

[profile.dev]
opt-level = 1

[[bench]]
name = "analyzers"
harness = false
